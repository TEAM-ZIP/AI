from fastapi import APIRouter
from pydantic import BaseModel
import os, json, requests
from dotenv import load_dotenv
from openai import OpenAI
from clients.chroma import book_collection, profile_collection
import re

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

router = APIRouter()
user_histories: dict[str, list[dict]] = {}

class ChatRequest(BaseModel):
    user_id: str
    user_name: str
    message: str

@router.post("/chat")
async def chat(req: ChatRequest):
    profile = profile_collection.get(ids=[req.user_id], include=["embeddings"])

    # ì‚¬ìš©ì íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if req.user_id not in user_histories:
        user_histories[req.user_id] = [{
            "role": "system",
            "content": f"ë„ˆëŠ” ì¹œì ˆí•˜ê³  ìœ ì¾Œí•œ ì„±ê²©ì˜ ì±—ë´‡ Bookieì•¼. ì‚¬ìš©ìì˜ ì´ë¦„ì€ '{req.user_name}'ì´ê³ , ì±… ì¶”ì²œì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì¶”ì²œì„ í•´ì¤˜. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì¼ìƒ ëŒ€í™”ì²˜ëŸ¼ ì‘ë‹µí•´ì¤˜."
        }]
    
    # ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
    user_histories[req.user_id].append({"role": "user", "content": req.message})

    # âœ… Step 1. ì‚¬ìš©ì ì„ë² ë”©ì´ ì—†ì„ ê²½ìš°
    if not profile or len(profile["embeddings"]) == 0:
        # 1-1. ì±… ê´€ë ¨ ì—¬ë¶€ íŒë‹¨
        intent_prompt = f"""
ë‹¤ìŒ ì‚¬ìš©ìì˜ ì…ë ¥ì´ ì±… ì¶”ì²œ ëŒ€í™”ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.
ì‘ë‹µì€ ë°˜ë“œì‹œ 'yes' ë˜ëŠ” 'no'ë¡œë§Œ í•´ì£¼ì„¸ìš”.

ì…ë ¥: "{req.message}"
"""
        intent_check = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì…ë ¥ì´ ì±… ê´€ë ¨ì¸ì§€ íŒë‹¨í•˜ëŠ” íŒë‹¨ê¸°ì•¼. ë°˜ë“œì‹œ yes ë˜ëŠ” noë¡œë§Œ ëŒ€ë‹µí•´."},
                {"role": "user", "content": intent_prompt},
            ],
        )
        is_book_related = intent_check.choices[0].message.content.strip().lower() == "yes"

        # 1-2. ì±… ê´€ë ¨ì´ ì•„ë‹ˆë¼ë©´: íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì‘ë‹µë§Œ
        if not is_book_related:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=user_histories[req.user_id]
            )
            reply = response.choices[0].message.content
            user_histories[req.user_id].append({"role": "assistant", "content": reply})
            return {
                "message": reply,
                "books": []
            }

        # 1-3. ì±… ê´€ë ¨ ì§ˆë¬¸ â†’ ì¸ê¸° ì±… ê¸°ë°˜ ì¶”ì²œ
        spring_res = requests.get(
            "http://3.38.79.143:8080/api/booksnap/reviews",
            params={"page": 0, "size": 2, "sort": "trend"}
        )
        if spring_res.status_code != 200:
            return {"message": "ë¦¬ë·°ê°€ ë¶€ì¡±í•˜ê³  ì¸ê¸° ë„ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆì–´ìš” ğŸ˜¢", "books": []}

        try:
            books_raw = spring_res.json().get("data", {}).get("booksnapPreview", [])[:2]
        except Exception as e:
            print("ğŸ”¥ spring ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬:", e)
            return {"message": "ì¸ê¸° ë„ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš” ğŸ˜¢", "books": []}

        book_cards = []
        for b in books_raw:
            info = b["bookInfo"]
            book_cards.append({
                "title": info.get("title"),
                "bookId": info.get("bookId"),
                "bookImageUrl": info.get("bookImageUrl")
            })

        book_titles = [book["title"] for book in book_cards]
        prompt = f"""ì‚¬ìš©ìì˜ ì…ë ¥: "{req.message}"

í˜„ì¬ ì´ ì‚¬ìš©ìì— ëŒ€í•œ ë¦¬ë·° ë°ì´í„°ê°€ ì—†ì–´, ë…ì„œ ì„±í–¥ì„ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
ì…ë ¥ì´ ì±… ì¶”ì²œì´ë¼ë©´ ì•„ë˜ ì¸ê¸° ë„ì„œ ì¤‘ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ì²œí•´ì¤˜.
ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ë”°ëœ»í•˜ê²Œ ëŒ€ë‹µí•´ì¤˜.

ë„ì„œ ëª©ë¡: {book_titles}
"""

        user_histories[req.user_id].append({"role": "user", "content": prompt})

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=user_histories[req.user_id],
        )
        reply = response.choices[0].message.content
        user_histories[req.user_id].append({"role": "assistant", "content": reply})

        return {
            "message": reply,
            "books": book_cards
        }

    # âœ… Step 2. ì‚¬ìš©ì ì„ë² ë”©ì´ ìˆëŠ” ê²½ìš°
    user_vector = profile["embeddings"][0]
    embedding_response = client.embeddings.create(
        model="text-embedding-3-small",
        input=req.message
    )
    question_vector = embedding_response.data[0].embedding
    combined_vector = [(u + q) / 2 for u, q in zip(user_vector, question_vector)]

    results = book_collection.query(
        query_embeddings=[combined_vector],
        n_results=10,
        include=["metadatas"]
    )
    candidates = results["metadatas"][0]
    print("í›„ë³´ ë„ì„œ 10ê¶Œ", candidates)

    rerank_prompt = f"""ì•„ë˜ëŠ” ì¶”ì²œ í›„ë³´ ë„ì„œ 10ê°œì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ '{req.message}'ì…ë‹ˆë‹¤.
ì´ ì§ˆë¬¸ì— ê°€ì¥ ì ì ˆí•œ ì±… 2ê°œë¥¼ ê³¨ë¼ JSON í˜•ì‹ ë¬¸ìì—´ ë°°ì—´ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
í›„ë³´ ë„ì„œ ëª©ë¡: {candidates}"""

    rerank_response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì˜ë¯¸ ê¸°ë°˜ìœ¼ë¡œ ì±…ì„ ë‹¤ì‹œ ì •ë ¬í•´ì£¼ëŠ” rerankerì•¼. JSON ë°°ì—´ë§Œ ì‘ë‹µí•´."},
            {"role": "user", "content": rerank_prompt},
        ],
    )
    response_text = rerank_response.choices[0].message.content.strip()
    response_text = re.sub(r"```json|```", "", response_text).strip()

    if not response_text:
        return {
        "message": "GPTê°€ ë„ì„œ ì¬ì •ë ¬ ì‘ë‹µì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
        "error": "ì‘ë‹µì´ ë¹„ì–´ ìˆìŒ"
        }

    try:
        top_titles = json.loads(response_text)
    except Exception as e:
        return {
        "message": "GPT ì‘ë‹µì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.",
        "raw": response_text,
        "error": str(e)
        }

    top_books = [book for book in candidates if book.get("title") in top_titles]

    final_prompt = f"""ì‚¬ìš©ìì˜ ì§ˆë¬¸: '{req.message}'\nì¶”ì²œ ë„ì„œ:\n{top_books}"""

    user_histories[req.user_id].append({"role": "user", "content": final_prompt})

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=user_histories[req.user_id]
    )
    reply = response.choices[0].message.content
    user_histories[req.user_id].append({"role": "assistant", "content": reply})

    book_cards = [
        {
            "title": book.get("title"),
            "bookId": book.get("bookId"),
            "bookImageUrl": book.get("bookImageUrl"),
        }
        for book in top_books
    ]

    return {
        "message": reply,
        "books": book_cards
    }
