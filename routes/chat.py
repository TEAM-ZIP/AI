from fastapi import APIRouter
from pydantic import BaseModel
import os, json, requests
from dotenv import load_dotenv
from openai import OpenAI
from clients.chroma import book_collection, profile_collection
import re

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

router = APIRouter()
user_histories: dict[str, list[dict]] = {}

class ChatRequest(BaseModel):
    user_id: str
    user_name: str
    message: str

@router.post("/chat")
async def chat(req: ChatRequest):
    profile = profile_collection.get(ids=[req.user_id], include=["embeddings"])

    # ì‚¬ìš©ì íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if req.user_id not in user_histories:
        user_histories[req.user_id] = [{
            "role": "system",
            "content": f"ë„ˆëŠ” ì¹œì ˆí•˜ê³  ìœ ì¾Œí•œ ì„±ê²©ì˜ ì±—ë´‡ Bookieì•¼. ì‚¬ìš©ìì˜ ì´ë¦„ì€ '{req.user_name}'ì´ê³ , ì±… ì¶”ì²œì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì¶”ì²œì„ í•´ì¤˜. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì¼ìƒ ëŒ€í™”ì²˜ëŸ¼ ì‘ë‹µí•´ì¤˜."
        }]
    
    # ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
    user_histories[req.user_id].append({"role": "user", "content": req.message})

    # âœ… Step 1. ì±… ê´€ë ¨ ì—¬ë¶€ íŒë‹¨
    # 1-1. ì±… ê´€ë ¨ ì—¬ë¶€ íŒë‹¨
    intent_prompt = f"""
    ë‹¤ìŒ ì‚¬ìš©ìì˜ ì…ë ¥ì´ ì±…ê³¼ ê´€ë ¨ëœ ëŒ€í™”ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”. 
    ì§ˆë¬¸ì´ ì±…ì„ ì§ì ‘ ì¶”ì²œí•´ë‹¬ë¼ëŠ” ëª…í™•í•œ ìš”ì²­ì´ ì•„ë‹ˆì–´ë„, 
    ì±…, ë…ì„œ, ì‘ê°€, ì¥ë¥´ ë“±ì— ëŒ€í•´ ì–¸ê¸‰í•˜ê±°ë‚˜ ê´€ì‹¬ì„ ë³´ì´ë©´ 'yes'ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”.

    ë°˜ë“œì‹œ 'yes' ë˜ëŠ” 'no'ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.

    ì…ë ¥: "{req.message}"
    """

    intent_check = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì…ë ¥ì´ ì±… ê´€ë ¨ì¸ì§€ íŒë‹¨í•˜ëŠ” íŒë‹¨ê¸°ì•¼. ë°˜ë“œì‹œ yes ë˜ëŠ” noë¡œë§Œ ëŒ€ë‹µí•´."},
            {"role": "user", "content": intent_prompt},
        ],
    )

    is_book_related = intent_check.choices[0].message.content.strip().lower() == "yes"
    print("ğŸ“Œ ì±… ê´€ë ¨ ì—¬ë¶€ íŒë‹¨ ì‘ë‹µ:", is_book_related)

    # 1-2. ì±… ê´€ë ¨ì´ ì•„ë‹ˆë¼ë©´: íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì‘ë‹µë§Œ
    if not is_book_related:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=user_histories[req.user_id]
        )
        reply = response.choices[0].message.content
        user_histories[req.user_id].append({"role": "assistant", "content": reply})
        return {
            "message": reply,
            "books": []
        }

    # âœ… Step 2. ì±… ê´€ë ¨ ì§ˆë¬¸
    # 2-1. ì„ë² ë”© ì—†ìœ¼ë©´
    if not profile or len(profile["embeddings"]) == 0:
        print("ğŸ“Œ ì„ë² ë”© ì—†ìŒ:")
        spring_res = requests.get(
            "http://3.38.79.143:8080/api/booksnap/reviews",
            params={"page": 0, "size": 2, "sort": "trend"}
        )
        if spring_res.status_code != 200:
            return {"message": "ë¦¬ë·°ê°€ ë¶€ì¡±í•˜ê³  ì¸ê¸° ë„ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆì–´ìš” ğŸ˜¢", "books": []}

        try:
            books_raw = spring_res.json().get("data", {}).get("booksnapPreview", [])[:2]
        except Exception as e:
            print("ğŸ”¥ spring ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬:", e)
            return {"message": "ì¸ê¸° ë„ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš” ğŸ˜¢", "books": []}

        book_cards = []
        for b in books_raw:
            info = b["bookInfo"]
            book_cards.append({
                "title": info.get("title"),
                "bookId": info.get("bookId"),
                "bookImageUrl": info.get("bookImageUrl")
            })

        book_titles = [book["title"] for book in book_cards]
        prompt = f"""ì‚¬ìš©ìì˜ ì…ë ¥: "{req.message}"

í˜„ì¬ ì´ ì‚¬ìš©ìì— ëŒ€í•œ ë¦¬ë·° ë°ì´í„°ê°€ ì—†ì–´, ë…ì„œ ì„±í–¥ì„ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
ì…ë ¥ì´ ì±… ì¶”ì²œì´ë¼ë©´ ì•„ë˜ ì¸ê¸° ë„ì„œ ì¤‘ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ì²œí•´ì¤˜.
ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ë”°ëœ»í•˜ê²Œ ëŒ€ë‹µí•´ì¤˜.

ë„ì„œ ëª©ë¡: {book_titles}
"""

        user_histories[req.user_id].append({"role": "user", "content": prompt})

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=user_histories[req.user_id],
        )
        reply = response.choices[0].message.content
        user_histories[req.user_id].append({"role": "assistant", "content": reply})

        return {
            "message": reply,
            "books": book_cards
        }

    # 2-2. ì‚¬ìš©ì ì„ë² ë”©ì´ ìˆëŠ” ê²½ìš°
    user_vector = profile["embeddings"][0]
    print("ğŸ“Œ ì„ë² ë”© ìˆìŒ")
    embedding_response = client.embeddings.create(
        model="text-embedding-3-small",
        input=req.message
    )
    question_vector = embedding_response.data[0].embedding
    combined_vector = [(u + q) / 2 for u, q in zip(user_vector, question_vector)]

    results = book_collection.query(
        query_embeddings=[combined_vector],
        n_results=10,
        include=["metadatas"]
    )

    candidates = results["metadatas"][0]

    simplified_candidates = [
        {"title": c.get("title", ""), "description": c.get("description", "")}
    for c in candidates
    ]

    rerank_prompt = f"""
ë‹¤ìŒì€ ì¶”ì²œ í›„ë³´ ë„ì„œ ëª©ë¡ì…ë‹ˆë‹¤:

{json.dumps(simplified_candidates, ensure_ascii=False, indent=2)}

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ "{req.message}"ì…ë‹ˆë‹¤.
ê°€ì¥ ì ì ˆí•œ ì±… 2ê¶Œì˜ **ì œëª©ë§Œ** JSON ë¬¸ìì—´ ë°°ì—´ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
ì˜ˆì‹œ: ["ì±…ì œëª©1", "ì±…ì œëª©2"]
"""


    rerank_response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì˜ë¯¸ ê¸°ë°˜ìœ¼ë¡œ ì±…ì„ ë‹¤ì‹œ ì •ë ¬í•´ì£¼ëŠ” rerankerì•¼. JSON ë°°ì—´ë§Œ ì‘ë‹µí•´."},
            {"role": "user", "content": rerank_prompt},
        ],
    )
    response_text = rerank_response.choices[0].message.content.strip()
    response_text = re.sub(r"```json|```", "", response_text).strip()
    print("ğŸ“Œ rerank í…ìŠ¤íŠ¸:", response_text)

    if not response_text:
        return {
        "message": "GPTê°€ ë„ì„œ ì¬ì •ë ¬ ì‘ë‹µì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
        "error": "ì‘ë‹µì´ ë¹„ì–´ ìˆìŒ"
        }

    parsed = json.loads(response_text)

    # ì‘ë‹µì´ ["ì±…ì œëª©1", "ì±…ì œëª©2"] í˜•íƒœì¼ ë•Œ
    if isinstance(parsed, list) and all(isinstance(x, str) for x in parsed):
        top_titles = parsed
    # ì‘ë‹µì´ [{"title": "ì œëª©"}] í˜•íƒœì¼ ë•Œ
    elif isinstance(parsed, list) and all(isinstance(x, dict) and "title" in x for x in parsed):
        top_titles = [x["title"] for x in parsed]
    else:
        return {
            "message": "GPT ì‘ë‹µ í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¬ë¼ìš” ğŸ˜¢",
            "raw": response_text,
            "error": "title íŒŒì‹± ì‹¤íŒ¨"
        }

    top_books = [book for book in candidates if book.get("title") in top_titles]
    print(top_books)

    if not top_books:
        return {
            "message": "ì¶”ì²œí•  ì±…ì´ ë¶€ì¡±í•´ìš”. ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ë³´ì‹¤ë˜ìš”? ğŸ˜Š",
            "books": []
        }
    
    final_prompt = f"""
    ì‚¬ìš©ìê°€ ì±… ì¶”ì²œì„ ìš”ì²­í–ˆê³ , ë‹¤ìŒ ë‘ ê¶Œì˜ ë„ì„œê°€ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.

    1. {top_books[0]["title"]}: {top_books[0]["description"]}
    2. {top_books[1]["title"]}: {top_books[1]["description"]}

    ê° ì±…ì„ ë”°ëœ»í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì†Œê°œí•´ì¤˜. 
    ì±… ì œëª©ê³¼ ì„¤ëª…ë§Œ ë‹´ê¸´ ê¸¸ì§€ ì•Šì€ ì¶”ì²œ ë©˜íŠ¸ë¡œ ë§ˆë¬´ë¦¬í•´ì¤˜.
    ë§í¬ë‚˜ ì´ë¯¸ì§€ë„ í¬í•¨í•˜ì§€ ë§ˆ.
    """

    user_histories[req.user_id].append({"role": "user", "content": final_prompt})

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=user_histories[req.user_id]
    )
    reply = response.choices[0].message.content
    user_histories[req.user_id].append({"role": "assistant", "content": reply})

    book_cards = [
        {
            "title": book.get("title"),
            "bookId": book.get("bookId"),
            "bookImageUrl": book.get("bookImageUrl"),
        }
        for book in top_books
    ]

    return {
        "message": reply,
        "books": book_cards
    }
